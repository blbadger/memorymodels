{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6605297114655526,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 1.5835689306259155,
      "learning_rate": 0.000497,
      "loss": 8.7205,
      "step": 500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 1.8306591510772705,
      "learning_rate": 0.0004987543859649123,
      "loss": 7.331125,
      "step": 1000
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 0.5814769268035889,
      "learning_rate": 0.0004975012531328321,
      "loss": 7.31085,
      "step": 1500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 0.6368722319602966,
      "learning_rate": 0.0004962481203007519,
      "loss": 7.262425,
      "step": 2000
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 0.7391442060470581,
      "learning_rate": 0.0004949949874686716,
      "loss": 7.21035,
      "step": 2500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.9459120035171509,
      "learning_rate": 0.0004937418546365915,
      "loss": 7.16645,
      "step": 3000
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 0.7842078804969788,
      "learning_rate": 0.0004924887218045113,
      "loss": 7.129225,
      "step": 3500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.862147331237793,
      "learning_rate": 0.0004912355889724311,
      "loss": 7.095175,
      "step": 4000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 7.079052925109863,
      "eval_runtime": 52.4569,
      "eval_samples_per_second": 953.163,
      "eval_steps_per_second": 7.454,
      "step": 4000
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.8931342363357544,
      "learning_rate": 0.0004899824561403509,
      "loss": 7.066025,
      "step": 4500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 1.2610528469085693,
      "learning_rate": 0.0004887293233082707,
      "loss": 7.034875,
      "step": 5000
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 1.2199177742004395,
      "learning_rate": 0.00048747619047619046,
      "loss": 7.005525,
      "step": 5500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 0.9489890336990356,
      "learning_rate": 0.0004862230576441103,
      "loss": 6.97645,
      "step": 6000
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 1.0104647874832153,
      "learning_rate": 0.00048497243107769423,
      "loss": 6.948975,
      "step": 6500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 0.9130913019180298,
      "learning_rate": 0.00048371929824561405,
      "loss": 6.92595,
      "step": 7000
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 0.9506559371948242,
      "learning_rate": 0.0004824661654135338,
      "loss": 6.9048,
      "step": 7500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 0.9493362307548523,
      "learning_rate": 0.0004812130325814537,
      "loss": 6.886375,
      "step": 8000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 6.874912261962891,
      "eval_runtime": 52.4805,
      "eval_samples_per_second": 952.735,
      "eval_steps_per_second": 7.45,
      "step": 8000
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 1.0474730730056763,
      "learning_rate": 0.00047996240601503763,
      "loss": 6.86645,
      "step": 8500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 0.9054779410362244,
      "learning_rate": 0.00047870927318295744,
      "loss": 6.850575,
      "step": 9000
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 1.030665636062622,
      "learning_rate": 0.0004774561403508772,
      "loss": 6.832325,
      "step": 9500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 0.9509415626525879,
      "learning_rate": 0.000476203007518797,
      "loss": 6.8181,
      "step": 10000
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 1.1214956045150757,
      "learning_rate": 0.00047495488721804516,
      "loss": 6.803525,
      "step": 10500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 1.019002079963684,
      "learning_rate": 0.0004737042606516291,
      "loss": 6.79,
      "step": 11000
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.9126511216163635,
      "learning_rate": 0.0004724511278195489,
      "loss": 6.77665,
      "step": 11500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 1.140963077545166,
      "learning_rate": 0.0004711979949874687,
      "loss": 6.763375,
      "step": 12000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 6.757307052612305,
      "eval_runtime": 57.0266,
      "eval_samples_per_second": 876.784,
      "eval_steps_per_second": 6.856,
      "step": 12000
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 1.0789507627487183,
      "learning_rate": 0.0004699448621553885,
      "loss": 6.75295,
      "step": 12500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 1.1111665964126587,
      "learning_rate": 0.00046869172932330826,
      "loss": 6.740925,
      "step": 13000
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 1.0529624223709106,
      "learning_rate": 0.0004674385964912281,
      "loss": 6.726225,
      "step": 13500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 1.195900559425354,
      "learning_rate": 0.0004661854636591479,
      "loss": 6.717175,
      "step": 14000
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 1.009901523590088,
      "learning_rate": 0.0004649323308270677,
      "loss": 6.70585,
      "step": 14500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.995738685131073,
      "learning_rate": 0.00046368170426065166,
      "loss": 6.69715,
      "step": 15000
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 1.0621414184570312,
      "learning_rate": 0.0004624285714285714,
      "loss": 6.687,
      "step": 15500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 1.1795670986175537,
      "learning_rate": 0.00046117543859649124,
      "loss": 6.675875,
      "step": 16000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 6.670377731323242,
      "eval_runtime": 52.4824,
      "eval_samples_per_second": 952.7,
      "eval_steps_per_second": 7.45,
      "step": 16000
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 1.1294974088668823,
      "learning_rate": 0.000459922305764411,
      "loss": 6.6684,
      "step": 16500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 1.2127147912979126,
      "learning_rate": 0.000458671679197995,
      "loss": 6.657575,
      "step": 17000
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 1.2278599739074707,
      "learning_rate": 0.00045741854636591477,
      "loss": 6.64805,
      "step": 17500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 1.1418193578720093,
      "learning_rate": 0.00045616541353383464,
      "loss": 6.64025,
      "step": 18000
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 1.0983760356903076,
      "learning_rate": 0.0004549122807017544,
      "loss": 6.631525,
      "step": 18500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 1.0571343898773193,
      "learning_rate": 0.0004536591478696742,
      "loss": 6.623975,
      "step": 19000
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 1.2359989881515503,
      "learning_rate": 0.00045240852130325817,
      "loss": 6.61555,
      "step": 19500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 1.1961675882339478,
      "learning_rate": 0.00045115538847117793,
      "loss": 6.60625,
      "step": 20000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 6.602057933807373,
      "eval_runtime": 54.599,
      "eval_samples_per_second": 915.768,
      "eval_steps_per_second": 7.161,
      "step": 20000
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 1.0310657024383545,
      "learning_rate": 0.00044990225563909774,
      "loss": 6.5996,
      "step": 20500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 1.1662092208862305,
      "learning_rate": 0.0004486491228070175,
      "loss": 6.5915,
      "step": 21000
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 1.1033748388290405,
      "learning_rate": 0.0004473984962406015,
      "loss": 6.584725,
      "step": 21500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 1.1455761194229126,
      "learning_rate": 0.0004461453634085213,
      "loss": 6.5777,
      "step": 22000
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 1.2115753889083862,
      "learning_rate": 0.00044489223057644114,
      "loss": 6.570925,
      "step": 22500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 1.0524427890777588,
      "learning_rate": 0.0004436390977443609,
      "loss": 6.563425,
      "step": 23000
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 1.06134033203125,
      "learning_rate": 0.0004423884711779449,
      "loss": 6.5578,
      "step": 23500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 1.103478193283081,
      "learning_rate": 0.00044113533834586467,
      "loss": 6.5526,
      "step": 24000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 6.549455642700195,
      "eval_runtime": 56.9508,
      "eval_samples_per_second": 877.951,
      "eval_steps_per_second": 6.866,
      "step": 24000
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 1.0880986452102661,
      "learning_rate": 0.0004398822055137845,
      "loss": 6.545275,
      "step": 24500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 1.120976209640503,
      "learning_rate": 0.00043862907268170425,
      "loss": 6.537875,
      "step": 25000
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 1.1554126739501953,
      "learning_rate": 0.0004373759398496241,
      "loss": 6.5308,
      "step": 25500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 1.0556175708770752,
      "learning_rate": 0.000436125313283208,
      "loss": 6.52595,
      "step": 26000
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 1.1345939636230469,
      "learning_rate": 0.00043487218045112783,
      "loss": 6.51885,
      "step": 26500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 1.1386256217956543,
      "learning_rate": 0.00043361904761904764,
      "loss": 6.51435,
      "step": 27000
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 1.1189336776733398,
      "learning_rate": 0.0004323659147869674,
      "loss": 6.508425,
      "step": 27500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 1.1310921907424927,
      "learning_rate": 0.0004311127819548872,
      "loss": 6.500175,
      "step": 28000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 6.499207496643066,
      "eval_runtime": 52.5183,
      "eval_samples_per_second": 952.049,
      "eval_steps_per_second": 7.445,
      "step": 28000
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.9737740755081177,
      "learning_rate": 0.00042986215538847117,
      "loss": 6.49875,
      "step": 28500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 1.063246726989746,
      "learning_rate": 0.000428609022556391,
      "loss": 6.491025,
      "step": 29000
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 1.0243916511535645,
      "learning_rate": 0.00042735588972431075,
      "loss": 6.484225,
      "step": 29500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 1.071775197982788,
      "learning_rate": 0.0004261027568922306,
      "loss": 6.48175,
      "step": 30000
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 1.245012640953064,
      "learning_rate": 0.00042485213032581457,
      "loss": 6.47365,
      "step": 30500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 1.0276265144348145,
      "learning_rate": 0.00042359899749373433,
      "loss": 6.471025,
      "step": 31000
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.9948335289955139,
      "learning_rate": 0.00042234586466165415,
      "loss": 6.46545,
      "step": 31500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 1.080277442932129,
      "learning_rate": 0.0004210927318295739,
      "loss": 6.46135,
      "step": 32000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 6.458170413970947,
      "eval_runtime": 52.5899,
      "eval_samples_per_second": 950.753,
      "eval_steps_per_second": 7.435,
      "step": 32000
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 1.069152593612671,
      "learning_rate": 0.0004198395989974937,
      "loss": 6.4565,
      "step": 32500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.993802547454834,
      "learning_rate": 0.0004185889724310777,
      "loss": 6.450675,
      "step": 33000
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 1.0660605430603027,
      "learning_rate": 0.0004173358395989975,
      "loss": 6.44625,
      "step": 33500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 1.061556100845337,
      "learning_rate": 0.0004160827067669173,
      "loss": 6.442275,
      "step": 34000
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 1.1078130006790161,
      "learning_rate": 0.0004148295739348371,
      "loss": 6.438525,
      "step": 34500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.987618088722229,
      "learning_rate": 0.0004135764411027569,
      "loss": 6.433475,
      "step": 35000
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 1.1285206079483032,
      "learning_rate": 0.0004123258145363409,
      "loss": 6.4292,
      "step": 35500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 1.0791245698928833,
      "learning_rate": 0.00041107268170426065,
      "loss": 6.423675,
      "step": 36000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 6.423233985900879,
      "eval_runtime": 52.4832,
      "eval_samples_per_second": 952.686,
      "eval_steps_per_second": 7.45,
      "step": 36000
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 1.172794222831726,
      "learning_rate": 0.00040981954887218047,
      "loss": 6.4191,
      "step": 36500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 1.0730762481689453,
      "learning_rate": 0.00040856641604010023,
      "loss": 6.41755,
      "step": 37000
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 1.1796798706054688,
      "learning_rate": 0.0004073132832080201,
      "loss": 6.413025,
      "step": 37500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 1.0438807010650635,
      "learning_rate": 0.00040606015037593986,
      "loss": 6.4072,
      "step": 38000
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 1.1948318481445312,
      "learning_rate": 0.0004048095238095238,
      "loss": 6.406625,
      "step": 38500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 1.0517148971557617,
      "learning_rate": 0.00040355639097744363,
      "loss": 6.40225,
      "step": 39000
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 1.0159735679626465,
      "learning_rate": 0.0004023032581453634,
      "loss": 6.3979,
      "step": 39500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 1.047249674797058,
      "learning_rate": 0.0004010501253132832,
      "loss": 6.393125,
      "step": 40000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 6.3919572830200195,
      "eval_runtime": 52.6948,
      "eval_samples_per_second": 948.861,
      "eval_steps_per_second": 7.42,
      "step": 40000
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 1.2182878255844116,
      "learning_rate": 0.00039979699248120297,
      "loss": 6.389025,
      "step": 40500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 1.0513012409210205,
      "learning_rate": 0.00039854385964912284,
      "loss": 6.38615,
      "step": 41000
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 1.0320795774459839,
      "learning_rate": 0.0003972907268170426,
      "loss": 6.38315,
      "step": 41500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 1.0507712364196777,
      "learning_rate": 0.0003960401002506266,
      "loss": 6.37875,
      "step": 42000
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.9546504616737366,
      "learning_rate": 0.00039478696741854637,
      "loss": 6.376525,
      "step": 42500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 1.1258575916290283,
      "learning_rate": 0.0003935338345864662,
      "loss": 6.373725,
      "step": 43000
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 1.236541986465454,
      "learning_rate": 0.00039228070175438594,
      "loss": 6.368875,
      "step": 43500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 1.0439070463180542,
      "learning_rate": 0.0003910275689223058,
      "loss": 6.36595,
      "step": 44000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 6.365041255950928,
      "eval_runtime": 52.4884,
      "eval_samples_per_second": 952.592,
      "eval_steps_per_second": 7.449,
      "step": 44000
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 1.1978298425674438,
      "learning_rate": 0.0003897769423558897,
      "loss": 6.362675,
      "step": 44500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 1.1580179929733276,
      "learning_rate": 0.0003885238095238096,
      "loss": 6.35985,
      "step": 45000
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 1.0669665336608887,
      "learning_rate": 0.00038727067669172934,
      "loss": 6.3559,
      "step": 45500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 1.0667284727096558,
      "learning_rate": 0.0003860200501253133,
      "loss": 6.35245,
      "step": 46000
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 1.0307382345199585,
      "learning_rate": 0.0003847669172932331,
      "loss": 6.349675,
      "step": 46500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 1.016126036643982,
      "learning_rate": 0.00038351378446115287,
      "loss": 6.346825,
      "step": 47000
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 1.107471227645874,
      "learning_rate": 0.0003822606516290727,
      "loss": 6.34255,
      "step": 47500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 1.0781210660934448,
      "learning_rate": 0.00038100751879699245,
      "loss": 6.337975,
      "step": 48000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 6.339740753173828,
      "eval_runtime": 57.027,
      "eval_samples_per_second": 876.777,
      "eval_steps_per_second": 6.856,
      "step": 48000
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 1.110742449760437,
      "learning_rate": 0.0003797543859649123,
      "loss": 6.335775,
      "step": 48500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 1.1432926654815674,
      "learning_rate": 0.0003785012531328321,
      "loss": 6.33335,
      "step": 49000
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 1.0951850414276123,
      "learning_rate": 0.0003772481203007519,
      "loss": 6.33065,
      "step": 49500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 1.2003827095031738,
      "learning_rate": 0.00037599749373433584,
      "loss": 6.328125,
      "step": 50000
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 1.0964407920837402,
      "learning_rate": 0.00037474436090225566,
      "loss": 6.32515,
      "step": 50500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 1.1182761192321777,
      "learning_rate": 0.0003734912280701754,
      "loss": 6.322025,
      "step": 51000
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 1.0101503133773804,
      "learning_rate": 0.00037223809523809524,
      "loss": 6.324475,
      "step": 51500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 1.0486255884170532,
      "learning_rate": 0.00037098496240601505,
      "loss": 6.317675,
      "step": 52000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 6.315536022186279,
      "eval_runtime": 52.4936,
      "eval_samples_per_second": 952.497,
      "eval_steps_per_second": 7.449,
      "step": 52000
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 1.0790128707885742,
      "learning_rate": 0.00036973182957393487,
      "loss": 6.313475,
      "step": 52500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 1.1048787832260132,
      "learning_rate": 0.0003684812030075188,
      "loss": 6.311775,
      "step": 53000
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 1.0568745136260986,
      "learning_rate": 0.0003672280701754386,
      "loss": 6.3062,
      "step": 53500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 1.1719167232513428,
      "learning_rate": 0.0003659749373433584,
      "loss": 6.307325,
      "step": 54000
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 1.136611819267273,
      "learning_rate": 0.00036472180451127816,
      "loss": 6.304825,
      "step": 54500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 1.0529375076293945,
      "learning_rate": 0.00036346867167919803,
      "loss": 6.3013,
      "step": 55000
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 1.0051078796386719,
      "learning_rate": 0.0003622180451127819,
      "loss": 6.29825,
      "step": 55500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 1.1618767976760864,
      "learning_rate": 0.0003609649122807018,
      "loss": 6.2971,
      "step": 56000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 6.29449987411499,
      "eval_runtime": 56.57,
      "eval_samples_per_second": 883.861,
      "eval_steps_per_second": 6.912,
      "step": 56000
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 1.1603631973266602,
      "learning_rate": 0.00035971177944862156,
      "loss": 6.29435,
      "step": 56500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 1.0698117017745972,
      "learning_rate": 0.0003584586466165414,
      "loss": 6.291225,
      "step": 57000
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 1.036697506904602,
      "learning_rate": 0.0003572080200501253,
      "loss": 6.288,
      "step": 57500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 1.1180864572525024,
      "learning_rate": 0.00035595488721804514,
      "loss": 6.285825,
      "step": 58000
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 1.2660537958145142,
      "learning_rate": 0.0003547042606516291,
      "loss": 6.28495,
      "step": 58500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 1.1117355823516846,
      "learning_rate": 0.00035345112781954885,
      "loss": 6.282775,
      "step": 59000
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 1.1197024583816528,
      "learning_rate": 0.00035219799498746867,
      "loss": 6.27985,
      "step": 59500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 1.2006726264953613,
      "learning_rate": 0.00035094486215538843,
      "loss": 6.2769,
      "step": 60000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 6.276985168457031,
      "eval_runtime": 52.5993,
      "eval_samples_per_second": 950.583,
      "eval_steps_per_second": 7.434,
      "step": 60000
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 1.1897696256637573,
      "learning_rate": 0.0003496917293233083,
      "loss": 6.27265,
      "step": 60500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 1.1822168827056885,
      "learning_rate": 0.00034843859649122806,
      "loss": 6.272125,
      "step": 61000
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 1.0388120412826538,
      "learning_rate": 0.0003471854636591479,
      "loss": 6.268175,
      "step": 61500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 1.127260446548462,
      "learning_rate": 0.00034593233082706764,
      "loss": 6.265875,
      "step": 62000
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 1.0954043865203857,
      "learning_rate": 0.00034467919799498745,
      "loss": 6.265425,
      "step": 62500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 1.0380003452301025,
      "learning_rate": 0.0003434285714285714,
      "loss": 6.263225,
      "step": 63000
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 1.0708352327346802,
      "learning_rate": 0.0003421754385964913,
      "loss": 6.259725,
      "step": 63500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 1.1577842235565186,
      "learning_rate": 0.00034092230576441104,
      "loss": 6.2582,
      "step": 64000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 6.258029460906982,
      "eval_runtime": 52.5185,
      "eval_samples_per_second": 952.046,
      "eval_steps_per_second": 7.445,
      "step": 64000
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 1.1499786376953125,
      "learning_rate": 0.00033966917293233085,
      "loss": 6.25855,
      "step": 64500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 1.207192063331604,
      "learning_rate": 0.0003384160401002506,
      "loss": 6.25245,
      "step": 65000
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 1.1971219778060913,
      "learning_rate": 0.00033716290726817043,
      "loss": 6.252025,
      "step": 65500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 1.00548255443573,
      "learning_rate": 0.00033590977443609025,
      "loss": 6.25155,
      "step": 66000
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 1.1048777103424072,
      "learning_rate": 0.0003346591478696742,
      "loss": 6.2475,
      "step": 66500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 1.0393238067626953,
      "learning_rate": 0.000333406015037594,
      "loss": 6.242975,
      "step": 67000
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 1.0804505348205566,
      "learning_rate": 0.00033215288220551383,
      "loss": 6.24135,
      "step": 67500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 1.137347936630249,
      "learning_rate": 0.0003308997493734336,
      "loss": 6.24235,
      "step": 68000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 6.240059852600098,
      "eval_runtime": 52.5189,
      "eval_samples_per_second": 952.037,
      "eval_steps_per_second": 7.445,
      "step": 68000
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 1.0588358640670776,
      "learning_rate": 0.0003296466165413534,
      "loss": 6.238775,
      "step": 68500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 1.0818077325820923,
      "learning_rate": 0.00032839348370927317,
      "loss": 6.2368,
      "step": 69000
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 1.1024914979934692,
      "learning_rate": 0.0003271428571428571,
      "loss": 6.237675,
      "step": 69500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 1.0610812902450562,
      "learning_rate": 0.00032588972431077693,
      "loss": 6.232925,
      "step": 70000
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 1.1944935321807861,
      "learning_rate": 0.00032463659147869675,
      "loss": 6.232525,
      "step": 70500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 1.1305515766143799,
      "learning_rate": 0.00032338596491228075,
      "loss": 6.229725,
      "step": 71000
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 1.152023434638977,
      "learning_rate": 0.0003221328320802005,
      "loss": 6.227275,
      "step": 71500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 1.1874233484268188,
      "learning_rate": 0.00032087969924812033,
      "loss": 6.224575,
      "step": 72000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 6.225545406341553,
      "eval_runtime": 56.5039,
      "eval_samples_per_second": 884.895,
      "eval_steps_per_second": 6.92,
      "step": 72000
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 1.2035081386566162,
      "learning_rate": 0.0003196265664160401,
      "loss": 6.22455,
      "step": 72500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 1.060746431350708,
      "learning_rate": 0.0003183734335839599,
      "loss": 6.22285,
      "step": 73000
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 1.237480640411377,
      "learning_rate": 0.00031712030075187967,
      "loss": 6.218225,
      "step": 73500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 1.1571342945098877,
      "learning_rate": 0.00031586716791979954,
      "loss": 6.2206,
      "step": 74000
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 1.1489733457565308,
      "learning_rate": 0.0003146140350877193,
      "loss": 6.215725,
      "step": 74500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 1.2282675504684448,
      "learning_rate": 0.0003133609022556391,
      "loss": 6.21345,
      "step": 75000
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 1.08598792552948,
      "learning_rate": 0.0003121077694235589,
      "loss": 6.206275,
      "step": 75500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 1.2121206521987915,
      "learning_rate": 0.0003108546365914787,
      "loss": 6.202275,
      "step": 76000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 6.2106122970581055,
      "eval_runtime": 52.4755,
      "eval_samples_per_second": 952.826,
      "eval_steps_per_second": 7.451,
      "step": 76000
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 1.3260793685913086,
      "learning_rate": 0.0003096015037593985,
      "loss": 6.20135,
      "step": 76500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 1.3886677026748657,
      "learning_rate": 0.00030835087719298246,
      "loss": 6.1982,
      "step": 77000
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 1.1316125392913818,
      "learning_rate": 0.0003070977443609023,
      "loss": 6.198275,
      "step": 77500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 1.1071746349334717,
      "learning_rate": 0.00030584461152882204,
      "loss": 6.19645,
      "step": 78000
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 1.14564847946167,
      "learning_rate": 0.00030459147869674186,
      "loss": 6.19395,
      "step": 78500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 1.1084245443344116,
      "learning_rate": 0.0003033408521303258,
      "loss": 6.19515,
      "step": 79000
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 1.126076579093933,
      "learning_rate": 0.00030209273182957394,
      "loss": 6.192875,
      "step": 79500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 1.0729355812072754,
      "learning_rate": 0.00030083959899749376,
      "loss": 6.190925,
      "step": 80000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 6.196508884429932,
      "eval_runtime": 56.5422,
      "eval_samples_per_second": 884.295,
      "eval_steps_per_second": 6.915,
      "step": 80000
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 1.116613507270813,
      "learning_rate": 0.0002995864661654135,
      "loss": 6.189175,
      "step": 80500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 1.3576879501342773,
      "learning_rate": 0.00029833333333333334,
      "loss": 6.188575,
      "step": 81000
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 1.1466991901397705,
      "learning_rate": 0.0002970802005012531,
      "loss": 6.18465,
      "step": 81500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 1.3680387735366821,
      "learning_rate": 0.00029582706766917297,
      "loss": 6.184825,
      "step": 82000
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 1.2525705099105835,
      "learning_rate": 0.00029457393483709273,
      "loss": 6.1824,
      "step": 82500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 1.2080481052398682,
      "learning_rate": 0.00029332080200501255,
      "loss": 6.182875,
      "step": 83000
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 1.3270833492279053,
      "learning_rate": 0.0002920676691729323,
      "loss": 6.179575,
      "step": 83500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 1.3126745223999023,
      "learning_rate": 0.0002908145363408521,
      "loss": 6.17795,
      "step": 84000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 6.183575630187988,
      "eval_runtime": 52.4851,
      "eval_samples_per_second": 952.652,
      "eval_steps_per_second": 7.45,
      "step": 84000
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 1.174683690071106,
      "learning_rate": 0.0002895614035087719,
      "loss": 6.176775,
      "step": 84500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 1.385680079460144,
      "learning_rate": 0.00028830827067669176,
      "loss": 6.1762,
      "step": 85000
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 1.0473204851150513,
      "learning_rate": 0.0002870551378446115,
      "loss": 6.174725,
      "step": 85500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 1.1439673900604248,
      "learning_rate": 0.0002858045112781955,
      "loss": 6.174725,
      "step": 86000
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 1.3157455921173096,
      "learning_rate": 0.0002845513784461153,
      "loss": 6.1698,
      "step": 86500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 1.1126351356506348,
      "learning_rate": 0.0002832982456140351,
      "loss": 6.17115,
      "step": 87000
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 1.2313464879989624,
      "learning_rate": 0.00028204511278195486,
      "loss": 6.16775,
      "step": 87500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 1.1248984336853027,
      "learning_rate": 0.00028079448621553887,
      "loss": 6.163475,
      "step": 88000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 6.172814846038818,
      "eval_runtime": 52.498,
      "eval_samples_per_second": 952.417,
      "eval_steps_per_second": 7.448,
      "step": 88000
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 1.2051341533660889,
      "learning_rate": 0.00027954135338345863,
      "loss": 6.164975,
      "step": 88500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 1.1729950904846191,
      "learning_rate": 0.0002782882205513785,
      "loss": 6.164175,
      "step": 89000
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 1.3404377698898315,
      "learning_rate": 0.00027703508771929826,
      "loss": 6.164475,
      "step": 89500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 1.3762648105621338,
      "learning_rate": 0.0002757844611528822,
      "loss": 6.1608,
      "step": 90000
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 1.3305391073226929,
      "learning_rate": 0.00027453132832080203,
      "loss": 6.15885,
      "step": 90500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 1.3320242166519165,
      "learning_rate": 0.0002732781954887218,
      "loss": 6.1569,
      "step": 91000
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 1.0936952829360962,
      "learning_rate": 0.0002720250626566416,
      "loss": 6.155575,
      "step": 91500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 1.1691778898239136,
      "learning_rate": 0.00027077443609022556,
      "loss": 6.1559,
      "step": 92000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 6.159271717071533,
      "eval_runtime": 57.16,
      "eval_samples_per_second": 874.738,
      "eval_steps_per_second": 6.84,
      "step": 92000
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 1.282031536102295,
      "learning_rate": 0.00026952130325814537,
      "loss": 6.154675,
      "step": 92500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 1.1246720552444458,
      "learning_rate": 0.0002682681704260652,
      "loss": 6.151625,
      "step": 93000
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 1.3296403884887695,
      "learning_rate": 0.000267015037593985,
      "loss": 6.1518,
      "step": 93500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 1.2421808242797852,
      "learning_rate": 0.00026576441102756895,
      "loss": 6.149425,
      "step": 94000
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 1.2831852436065674,
      "learning_rate": 0.0002645112781954887,
      "loss": 6.148425,
      "step": 94500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 1.2967687845230103,
      "learning_rate": 0.0002632606516290727,
      "loss": 6.1464,
      "step": 95000
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 1.3573787212371826,
      "learning_rate": 0.0002620075187969925,
      "loss": 6.147075,
      "step": 95500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 1.1786068677902222,
      "learning_rate": 0.0002607543859649123,
      "loss": 6.14425,
      "step": 96000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 6.1486029624938965,
      "eval_runtime": 52.4681,
      "eval_samples_per_second": 952.96,
      "eval_steps_per_second": 7.452,
      "step": 96000
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 1.3602427244186401,
      "learning_rate": 0.00025950125313283206,
      "loss": 6.143,
      "step": 96500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 1.2317155599594116,
      "learning_rate": 0.0002582481203007519,
      "loss": 6.143425,
      "step": 97000
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 1.3067119121551514,
      "learning_rate": 0.0002569949874686717,
      "loss": 6.140625,
      "step": 97500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 1.2156039476394653,
      "learning_rate": 0.0002557418546365915,
      "loss": 6.139225,
      "step": 98000
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 1.2491029500961304,
      "learning_rate": 0.00025448872180451127,
      "loss": 6.1378,
      "step": 98500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 1.2293055057525635,
      "learning_rate": 0.0002532380952380953,
      "loss": 6.13455,
      "step": 99000
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 1.1384460926055908,
      "learning_rate": 0.00025198496240601503,
      "loss": 6.13455,
      "step": 99500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 1.3544608354568481,
      "learning_rate": 0.00025073182957393485,
      "loss": 6.13335,
      "step": 100000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 6.137808322906494,
      "eval_runtime": 52.4868,
      "eval_samples_per_second": 952.621,
      "eval_steps_per_second": 7.449,
      "step": 100000
    },
    {
      "epoch": 1.3369161800114404,
      "grad_norm": 1.2502679824829102,
      "learning_rate": 0.0002494786967418546,
      "loss": 6.132625,
      "step": 100500
    },
    {
      "epoch": 1.343567504290104,
      "grad_norm": 1.2001678943634033,
      "learning_rate": 0.0002482280701754386,
      "loss": 6.129,
      "step": 101000
    },
    {
      "epoch": 1.350218828568768,
      "grad_norm": 1.3881083726882935,
      "learning_rate": 0.00024697493734335843,
      "loss": 6.130225,
      "step": 101500
    },
    {
      "epoch": 1.3568701528474318,
      "grad_norm": 1.266749620437622,
      "learning_rate": 0.0002457218045112782,
      "loss": 6.12955,
      "step": 102000
    },
    {
      "epoch": 1.3635214771260957,
      "grad_norm": 1.156294345855713,
      "learning_rate": 0.000244468671679198,
      "loss": 6.127125,
      "step": 102500
    },
    {
      "epoch": 1.3701728014047596,
      "grad_norm": 1.2893236875534058,
      "learning_rate": 0.00024321804511278196,
      "loss": 6.12885,
      "step": 103000
    },
    {
      "epoch": 1.3768241256834235,
      "grad_norm": 1.184018611907959,
      "learning_rate": 0.00024196491228070175,
      "loss": 6.1261,
      "step": 103500
    },
    {
      "epoch": 1.3834754499620874,
      "grad_norm": 1.3979527950286865,
      "learning_rate": 0.00024071177944862154,
      "loss": 6.12385,
      "step": 104000
    },
    {
      "epoch": 1.3834754499620874,
      "eval_loss": 6.128575801849365,
      "eval_runtime": 52.533,
      "eval_samples_per_second": 951.782,
      "eval_steps_per_second": 7.443,
      "step": 104000
    },
    {
      "epoch": 1.3901267742407513,
      "grad_norm": 1.3538768291473389,
      "learning_rate": 0.00023946115288220552,
      "loss": 6.12355,
      "step": 104500
    },
    {
      "epoch": 1.3967780985194151,
      "grad_norm": 1.250972032546997,
      "learning_rate": 0.00023820802005012533,
      "loss": 6.12085,
      "step": 105000
    },
    {
      "epoch": 1.403429422798079,
      "grad_norm": 1.2555702924728394,
      "learning_rate": 0.00023695488721804512,
      "loss": 6.1197,
      "step": 105500
    },
    {
      "epoch": 1.410080747076743,
      "grad_norm": 1.316633701324463,
      "learning_rate": 0.0002357017543859649,
      "loss": 6.1199,
      "step": 106000
    },
    {
      "epoch": 1.4167320713554068,
      "grad_norm": 1.422273874282837,
      "learning_rate": 0.00023444862155388473,
      "loss": 6.1178,
      "step": 106500
    },
    {
      "epoch": 1.4233833956340707,
      "grad_norm": 1.2295236587524414,
      "learning_rate": 0.00023319548872180451,
      "loss": 6.114375,
      "step": 107000
    },
    {
      "epoch": 1.4300347199127346,
      "grad_norm": 1.3658437728881836,
      "learning_rate": 0.0002319448621553885,
      "loss": 6.1169,
      "step": 107500
    },
    {
      "epoch": 1.4366860441913984,
      "grad_norm": 1.2496297359466553,
      "learning_rate": 0.00023069172932330828,
      "loss": 6.114875,
      "step": 108000
    },
    {
      "epoch": 1.4366860441913984,
      "eval_loss": 6.117374897003174,
      "eval_runtime": 53.7001,
      "eval_samples_per_second": 931.096,
      "eval_steps_per_second": 7.281,
      "step": 108000
    },
    {
      "epoch": 1.4433373684700623,
      "grad_norm": 1.1535180807113647,
      "learning_rate": 0.0002294385964912281,
      "loss": 6.11485,
      "step": 108500
    },
    {
      "epoch": 1.4499886927487262,
      "grad_norm": 1.3673679828643799,
      "learning_rate": 0.00022818546365914788,
      "loss": 6.11175,
      "step": 109000
    },
    {
      "epoch": 1.45664001702739,
      "grad_norm": 1.369492769241333,
      "learning_rate": 0.00022693233082706767,
      "loss": 6.106825,
      "step": 109500
    },
    {
      "epoch": 1.463291341306054,
      "grad_norm": 1.3430752754211426,
      "learning_rate": 0.00022568170426065162,
      "loss": 6.11245,
      "step": 110000
    },
    {
      "epoch": 1.4699426655847179,
      "grad_norm": 1.373542308807373,
      "learning_rate": 0.00022442857142857144,
      "loss": 6.107975,
      "step": 110500
    },
    {
      "epoch": 1.4765939898633818,
      "grad_norm": 1.3102177381515503,
      "learning_rate": 0.00022317543859649123,
      "loss": 6.108875,
      "step": 111000
    },
    {
      "epoch": 1.4832453141420456,
      "grad_norm": 1.580794334411621,
      "learning_rate": 0.00022192230576441102,
      "loss": 6.10665,
      "step": 111500
    },
    {
      "epoch": 1.4898966384207095,
      "grad_norm": 1.3488118648529053,
      "learning_rate": 0.00022066917293233083,
      "loss": 6.104775,
      "step": 112000
    },
    {
      "epoch": 1.4898966384207095,
      "eval_loss": 6.109240531921387,
      "eval_runtime": 52.6752,
      "eval_samples_per_second": 949.213,
      "eval_steps_per_second": 7.423,
      "step": 112000
    },
    {
      "epoch": 1.4965479626993734,
      "grad_norm": 1.4137693643569946,
      "learning_rate": 0.00021941604010025062,
      "loss": 6.104925,
      "step": 112500
    },
    {
      "epoch": 1.5031992869780373,
      "grad_norm": 1.3007447719573975,
      "learning_rate": 0.0002181629072681704,
      "loss": 6.10415,
      "step": 113000
    },
    {
      "epoch": 1.5098506112567012,
      "grad_norm": 1.2220596075057983,
      "learning_rate": 0.00021690977443609023,
      "loss": 6.100675,
      "step": 113500
    },
    {
      "epoch": 1.516501935535365,
      "grad_norm": 1.2671921253204346,
      "learning_rate": 0.00021565664160401002,
      "loss": 6.1005,
      "step": 114000
    },
    {
      "epoch": 1.523153259814029,
      "grad_norm": 1.2862387895584106,
      "learning_rate": 0.000214406015037594,
      "loss": 6.09945,
      "step": 114500
    },
    {
      "epoch": 1.5298045840926928,
      "grad_norm": 1.3300347328186035,
      "learning_rate": 0.00021315288220551378,
      "loss": 6.099575,
      "step": 115000
    },
    {
      "epoch": 1.5364559083713567,
      "grad_norm": 1.2830058336257935,
      "learning_rate": 0.0002118997493734336,
      "loss": 6.1006,
      "step": 115500
    },
    {
      "epoch": 1.5431072326500206,
      "grad_norm": 1.3421672582626343,
      "learning_rate": 0.0002106466165413534,
      "loss": 6.09635,
      "step": 116000
    },
    {
      "epoch": 1.5431072326500206,
      "eval_loss": 6.10044002532959,
      "eval_runtime": 52.4938,
      "eval_samples_per_second": 952.494,
      "eval_steps_per_second": 7.449,
      "step": 116000
    },
    {
      "epoch": 1.5497585569286845,
      "grad_norm": 1.4744333028793335,
      "learning_rate": 0.00020939598997493734,
      "loss": 6.094125,
      "step": 116500
    },
    {
      "epoch": 1.5564098812073484,
      "grad_norm": 1.4061615467071533,
      "learning_rate": 0.00020814285714285713,
      "loss": 6.0935,
      "step": 117000
    },
    {
      "epoch": 1.5630612054860122,
      "grad_norm": 1.2943681478500366,
      "learning_rate": 0.0002068922305764411,
      "loss": 6.0943,
      "step": 117500
    },
    {
      "epoch": 1.5697125297646761,
      "grad_norm": 1.26127028465271,
      "learning_rate": 0.0002056390977443609,
      "loss": 6.0916,
      "step": 118000
    },
    {
      "epoch": 1.57636385404334,
      "grad_norm": 1.2835960388183594,
      "learning_rate": 0.0002043859649122807,
      "loss": 6.0904,
      "step": 118500
    },
    {
      "epoch": 1.583015178322004,
      "grad_norm": 1.770104169845581,
      "learning_rate": 0.0002031328320802005,
      "loss": 6.089625,
      "step": 119000
    },
    {
      "epoch": 1.5896665026006678,
      "grad_norm": 1.5901447534561157,
      "learning_rate": 0.0002018796992481203,
      "loss": 6.08715,
      "step": 119500
    },
    {
      "epoch": 1.5963178268793317,
      "grad_norm": 1.35675847530365,
      "learning_rate": 0.00020062907268170426,
      "loss": 6.08855,
      "step": 120000
    },
    {
      "epoch": 1.5963178268793317,
      "eval_loss": 6.092303276062012,
      "eval_runtime": 55.8034,
      "eval_samples_per_second": 896.003,
      "eval_steps_per_second": 7.007,
      "step": 120000
    },
    {
      "epoch": 1.6029691511579955,
      "grad_norm": 1.5250351428985596,
      "learning_rate": 0.00019937593984962408,
      "loss": 6.088075,
      "step": 120500
    },
    {
      "epoch": 1.6096204754366594,
      "grad_norm": 1.2300978899002075,
      "learning_rate": 0.00019812280701754387,
      "loss": 6.087625,
      "step": 121000
    },
    {
      "epoch": 1.6162717997153233,
      "grad_norm": 1.2636785507202148,
      "learning_rate": 0.00019686967418546368,
      "loss": 6.085725,
      "step": 121500
    },
    {
      "epoch": 1.6229231239939872,
      "grad_norm": 1.2213678359985352,
      "learning_rate": 0.00019561654135338347,
      "loss": 6.0848,
      "step": 122000
    },
    {
      "epoch": 1.629574448272651,
      "grad_norm": 1.3259496688842773,
      "learning_rate": 0.00019436340852130326,
      "loss": 6.0839,
      "step": 122500
    },
    {
      "epoch": 1.636225772551315,
      "grad_norm": 1.4873207807540894,
      "learning_rate": 0.00019311027568922308,
      "loss": 6.08045,
      "step": 123000
    },
    {
      "epoch": 1.6428770968299788,
      "grad_norm": 1.1948390007019043,
      "learning_rate": 0.00019185714285714287,
      "loss": 6.081225,
      "step": 123500
    },
    {
      "epoch": 1.6495284211086427,
      "grad_norm": 1.352341890335083,
      "learning_rate": 0.00019060401002506266,
      "loss": 6.0802,
      "step": 124000
    },
    {
      "epoch": 1.6495284211086427,
      "eval_loss": 6.0831499099731445,
      "eval_runtime": 52.6134,
      "eval_samples_per_second": 950.328,
      "eval_steps_per_second": 7.432,
      "step": 124000
    },
    {
      "epoch": 1.6561797453873066,
      "grad_norm": 1.1825505495071411,
      "learning_rate": 0.0001893533834586466,
      "loss": 6.0803,
      "step": 124500
    },
    {
      "epoch": 1.6628310696659705,
      "grad_norm": 1.3742908239364624,
      "learning_rate": 0.00018810025062656642,
      "loss": 6.07725,
      "step": 125000
    },
    {
      "epoch": 1.6694823939446344,
      "grad_norm": 1.3496723175048828,
      "learning_rate": 0.0001868471177944862,
      "loss": 6.075025,
      "step": 125500
    },
    {
      "epoch": 1.6761337182232983,
      "grad_norm": 1.2790250778198242,
      "learning_rate": 0.000185593984962406,
      "loss": 6.07615,
      "step": 126000
    },
    {
      "epoch": 1.6827850425019621,
      "grad_norm": 1.267504096031189,
      "learning_rate": 0.00018434335839598998,
      "loss": 6.074475,
      "step": 126500
    },
    {
      "epoch": 1.689436366780626,
      "grad_norm": 1.2642284631729126,
      "learning_rate": 0.0001830902255639098,
      "loss": 6.0726,
      "step": 127000
    },
    {
      "epoch": 1.69608769105929,
      "grad_norm": 1.4498406648635864,
      "learning_rate": 0.00018183709273182958,
      "loss": 6.0732,
      "step": 127500
    },
    {
      "epoch": 1.7027390153379538,
      "grad_norm": 1.2206071615219116,
      "learning_rate": 0.00018058646616541356,
      "loss": 6.0722,
      "step": 128000
    },
    {
      "epoch": 1.7027390153379538,
      "eval_loss": 6.075150489807129,
      "eval_runtime": 52.4946,
      "eval_samples_per_second": 952.48,
      "eval_steps_per_second": 7.448,
      "step": 128000
    },
    {
      "epoch": 1.7093903396166177,
      "grad_norm": 1.3833674192428589,
      "learning_rate": 0.00017933333333333335,
      "loss": 6.071075,
      "step": 128500
    },
    {
      "epoch": 1.7160416638952816,
      "grad_norm": 1.3297888040542603,
      "learning_rate": 0.00017808020050125314,
      "loss": 6.0691,
      "step": 129000
    },
    {
      "epoch": 1.7226929881739454,
      "grad_norm": 1.3110369443893433,
      "learning_rate": 0.00017682706766917295,
      "loss": 6.071175,
      "step": 129500
    },
    {
      "epoch": 1.7293443124526093,
      "grad_norm": 1.3163819313049316,
      "learning_rate": 0.00017557393483709274,
      "loss": 6.067375,
      "step": 130000
    },
    {
      "epoch": 1.7359956367312732,
      "grad_norm": 1.3763456344604492,
      "learning_rate": 0.00017432080200501256,
      "loss": 6.06535,
      "step": 130500
    },
    {
      "epoch": 1.742646961009937,
      "grad_norm": 1.3652623891830444,
      "learning_rate": 0.00017307017543859648,
      "loss": 6.066575,
      "step": 131000
    },
    {
      "epoch": 1.749298285288601,
      "grad_norm": 1.5045998096466064,
      "learning_rate": 0.0001718170426065163,
      "loss": 6.066,
      "step": 131500
    },
    {
      "epoch": 1.7559496095672649,
      "grad_norm": 1.2421149015426636,
      "learning_rate": 0.00017056390977443608,
      "loss": 6.063925,
      "step": 132000
    },
    {
      "epoch": 1.7559496095672649,
      "eval_loss": 6.067946434020996,
      "eval_runtime": 52.5508,
      "eval_samples_per_second": 951.46,
      "eval_steps_per_second": 7.44,
      "step": 132000
    },
    {
      "epoch": 1.7626009338459288,
      "grad_norm": 1.3429996967315674,
      "learning_rate": 0.0001693107769423559,
      "loss": 6.062875,
      "step": 132500
    },
    {
      "epoch": 1.7692522581245926,
      "grad_norm": 1.3593801259994507,
      "learning_rate": 0.0001680576441102757,
      "loss": 6.061725,
      "step": 133000
    },
    {
      "epoch": 1.7759035824032565,
      "grad_norm": 1.3067967891693115,
      "learning_rate": 0.00016680451127819548,
      "loss": 6.063275,
      "step": 133500
    },
    {
      "epoch": 1.7825549066819204,
      "grad_norm": 1.3122947216033936,
      "learning_rate": 0.0001655513784461153,
      "loss": 6.06005,
      "step": 134000
    },
    {
      "epoch": 1.7892062309605843,
      "grad_norm": 1.424680471420288,
      "learning_rate": 0.00016429824561403508,
      "loss": 6.0623,
      "step": 134500
    },
    {
      "epoch": 1.7958575552392482,
      "grad_norm": 1.3531187772750854,
      "learning_rate": 0.00016304761904761906,
      "loss": 6.05955,
      "step": 135000
    },
    {
      "epoch": 1.802508879517912,
      "grad_norm": 1.5955138206481934,
      "learning_rate": 0.00016179448621553885,
      "loss": 6.05605,
      "step": 135500
    },
    {
      "epoch": 1.809160203796576,
      "grad_norm": 1.2978652715682983,
      "learning_rate": 0.00016054135338345866,
      "loss": 6.0593,
      "step": 136000
    },
    {
      "epoch": 1.809160203796576,
      "eval_loss": 6.0602617263793945,
      "eval_runtime": 52.5362,
      "eval_samples_per_second": 951.724,
      "eval_steps_per_second": 7.442,
      "step": 136000
    },
    {
      "epoch": 1.8158115280752398,
      "grad_norm": 1.4036221504211426,
      "learning_rate": 0.00015928822055137845,
      "loss": 6.056125,
      "step": 136500
    },
    {
      "epoch": 1.8224628523539037,
      "grad_norm": 1.4085197448730469,
      "learning_rate": 0.00015803508771929824,
      "loss": 6.0562,
      "step": 137000
    },
    {
      "epoch": 1.8291141766325676,
      "grad_norm": 1.2765347957611084,
      "learning_rate": 0.0001567844611528822,
      "loss": 6.05465,
      "step": 137500
    },
    {
      "epoch": 1.8357655009112315,
      "grad_norm": 1.4617276191711426,
      "learning_rate": 0.000155531328320802,
      "loss": 6.0549,
      "step": 138000
    },
    {
      "epoch": 1.8424168251898954,
      "grad_norm": 1.409314751625061,
      "learning_rate": 0.0001542781954887218,
      "loss": 6.05135,
      "step": 138500
    },
    {
      "epoch": 1.8490681494685592,
      "grad_norm": 1.422967553138733,
      "learning_rate": 0.0001530250626566416,
      "loss": 6.05165,
      "step": 139000
    },
    {
      "epoch": 1.8557194737472231,
      "grad_norm": 1.3678679466247559,
      "learning_rate": 0.00015177443609022556,
      "loss": 6.0527,
      "step": 139500
    },
    {
      "epoch": 1.862370798025887,
      "grad_norm": 1.5843181610107422,
      "learning_rate": 0.00015052130325814535,
      "loss": 6.05145,
      "step": 140000
    },
    {
      "epoch": 1.862370798025887,
      "eval_loss": 6.0549468994140625,
      "eval_runtime": 52.5114,
      "eval_samples_per_second": 952.175,
      "eval_steps_per_second": 7.446,
      "step": 140000
    },
    {
      "epoch": 1.8690221223045507,
      "grad_norm": 1.7165307998657227,
      "learning_rate": 0.00014926817042606517,
      "loss": 6.049525,
      "step": 140500
    },
    {
      "epoch": 1.8756734465832148,
      "grad_norm": 1.4444100856781006,
      "learning_rate": 0.00014801503759398496,
      "loss": 6.04995,
      "step": 141000
    },
    {
      "epoch": 1.8823247708618784,
      "grad_norm": 1.580451488494873,
      "learning_rate": 0.00014676441102756893,
      "loss": 6.048575,
      "step": 141500
    },
    {
      "epoch": 1.8889760951405425,
      "grad_norm": 1.4020994901657104,
      "learning_rate": 0.00014551127819548872,
      "loss": 6.04635,
      "step": 142000
    },
    {
      "epoch": 1.8956274194192062,
      "grad_norm": 1.4653555154800415,
      "learning_rate": 0.00014425814536340854,
      "loss": 6.048,
      "step": 142500
    },
    {
      "epoch": 1.9022787436978703,
      "grad_norm": 1.473634958267212,
      "learning_rate": 0.00014300501253132833,
      "loss": 6.044425,
      "step": 143000
    },
    {
      "epoch": 1.908930067976534,
      "grad_norm": 1.3719466924667358,
      "learning_rate": 0.00014175438596491228,
      "loss": 6.04545,
      "step": 143500
    },
    {
      "epoch": 1.915581392255198,
      "grad_norm": 1.4261362552642822,
      "learning_rate": 0.00014050125313283207,
      "loss": 6.0456,
      "step": 144000
    },
    {
      "epoch": 1.915581392255198,
      "eval_loss": 6.047088623046875,
      "eval_runtime": 56.9975,
      "eval_samples_per_second": 877.232,
      "eval_steps_per_second": 6.86,
      "step": 144000
    },
    {
      "epoch": 1.9222327165338617,
      "grad_norm": 1.409401297569275,
      "learning_rate": 0.00013924812030075188,
      "loss": 6.0421,
      "step": 144500
    },
    {
      "epoch": 1.9288840408125258,
      "grad_norm": 1.4657630920410156,
      "learning_rate": 0.00013799498746867167,
      "loss": 6.044325,
      "step": 145000
    },
    {
      "epoch": 1.9355353650911895,
      "grad_norm": 1.8108856678009033,
      "learning_rate": 0.00013674436090225565,
      "loss": 6.042825,
      "step": 145500
    },
    {
      "epoch": 1.9421866893698536,
      "grad_norm": 1.646211862564087,
      "learning_rate": 0.00013549122807017544,
      "loss": 6.038875,
      "step": 146000
    },
    {
      "epoch": 1.9488380136485173,
      "grad_norm": 1.522350788116455,
      "learning_rate": 0.00013423809523809525,
      "loss": 6.0401,
      "step": 146500
    },
    {
      "epoch": 1.9554893379271814,
      "grad_norm": 1.3524103164672852,
      "learning_rate": 0.00013298496240601504,
      "loss": 6.0415,
      "step": 147000
    },
    {
      "epoch": 1.962140662205845,
      "grad_norm": 1.3633382320404053,
      "learning_rate": 0.00013173182957393483,
      "loss": 6.038975,
      "step": 147500
    },
    {
      "epoch": 1.9687919864845091,
      "grad_norm": 1.6684341430664062,
      "learning_rate": 0.00013047869674185465,
      "loss": 6.03715,
      "step": 148000
    },
    {
      "epoch": 1.9687919864845091,
      "eval_loss": 6.0406494140625,
      "eval_runtime": 56.4519,
      "eval_samples_per_second": 885.71,
      "eval_steps_per_second": 6.926,
      "step": 148000
    },
    {
      "epoch": 1.9754433107631728,
      "grad_norm": 1.6116362810134888,
      "learning_rate": 0.00012922556390977444,
      "loss": 6.0352,
      "step": 148500
    },
    {
      "epoch": 1.982094635041837,
      "grad_norm": 1.4954406023025513,
      "learning_rate": 0.00012797243107769425,
      "loss": 6.03555,
      "step": 149000
    },
    {
      "epoch": 1.9887459593205006,
      "grad_norm": 1.460146427154541,
      "learning_rate": 0.0001267218045112782,
      "loss": 6.03425,
      "step": 149500
    },
    {
      "epoch": 1.9953972835991647,
      "grad_norm": 1.6010223627090454,
      "learning_rate": 0.00012546867167919802,
      "loss": 6.032,
      "step": 150000
    },
    {
      "epoch": 2.0020486078778283,
      "grad_norm": 1.3640871047973633,
      "learning_rate": 0.0001242155388471178,
      "loss": 6.031175,
      "step": 150500
    },
    {
      "epoch": 2.0086999321564925,
      "grad_norm": 1.362389087677002,
      "learning_rate": 0.00012296491228070176,
      "loss": 6.023975,
      "step": 151000
    },
    {
      "epoch": 2.015351256435156,
      "grad_norm": 1.6360455751419067,
      "learning_rate": 0.00012171177944862155,
      "loss": 6.020625,
      "step": 151500
    },
    {
      "epoch": 2.02200258071382,
      "grad_norm": 1.6157357692718506,
      "learning_rate": 0.00012045864661654135,
      "loss": 6.01805,
      "step": 152000
    },
    {
      "epoch": 2.02200258071382,
      "eval_loss": 6.035558223724365,
      "eval_runtime": 52.568,
      "eval_samples_per_second": 951.149,
      "eval_steps_per_second": 7.438,
      "step": 152000
    },
    {
      "epoch": 2.028653904992484,
      "grad_norm": 1.3786851167678833,
      "learning_rate": 0.00011920551378446115,
      "loss": 6.019375,
      "step": 152500
    },
    {
      "epoch": 2.035305229271148,
      "grad_norm": 1.4031590223312378,
      "learning_rate": 0.00011795238095238095,
      "loss": 6.018575,
      "step": 153000
    },
    {
      "epoch": 2.0419565535498116,
      "grad_norm": 1.5309252738952637,
      "learning_rate": 0.00011669924812030076,
      "loss": 6.017475,
      "step": 153500
    },
    {
      "epoch": 2.0486078778284758,
      "grad_norm": 1.379579782485962,
      "learning_rate": 0.00011544611528822054,
      "loss": 6.01845,
      "step": 154000
    },
    {
      "epoch": 2.0552592021071394,
      "grad_norm": 1.4518245458602905,
      "learning_rate": 0.00011419298245614035,
      "loss": 6.01885,
      "step": 154500
    },
    {
      "epoch": 2.0619105263858035,
      "grad_norm": 1.4624825716018677,
      "learning_rate": 0.00011294235588972432,
      "loss": 6.0147,
      "step": 155000
    },
    {
      "epoch": 2.068561850664467,
      "grad_norm": 1.2870903015136719,
      "learning_rate": 0.00011168922305764411,
      "loss": 6.015775,
      "step": 155500
    },
    {
      "epoch": 2.0752131749431313,
      "grad_norm": 1.3917771577835083,
      "learning_rate": 0.00011043609022556392,
      "loss": 6.017075,
      "step": 156000
    },
    {
      "epoch": 2.0752131749431313,
      "eval_loss": 6.03112268447876,
      "eval_runtime": 52.713,
      "eval_samples_per_second": 948.533,
      "eval_steps_per_second": 7.418,
      "step": 156000
    },
    {
      "epoch": 2.081864499221795,
      "grad_norm": 1.2767308950424194,
      "learning_rate": 0.00010918295739348372,
      "loss": 6.01355,
      "step": 156500
    },
    {
      "epoch": 2.088515823500459,
      "grad_norm": 1.277398705482483,
      "learning_rate": 0.00010793483709273183,
      "loss": 6.014175,
      "step": 157000
    },
    {
      "epoch": 2.0951671477791227,
      "grad_norm": 1.4503133296966553,
      "learning_rate": 0.00010668170426065163,
      "loss": 6.014575,
      "step": 157500
    },
    {
      "epoch": 2.101818472057787,
      "grad_norm": 1.585871934890747,
      "learning_rate": 0.00010542857142857143,
      "loss": 6.0139,
      "step": 158000
    },
    {
      "epoch": 2.1084697963364505,
      "grad_norm": 1.510521411895752,
      "learning_rate": 0.00010417543859649122,
      "loss": 6.012425,
      "step": 158500
    },
    {
      "epoch": 2.1151211206151146,
      "grad_norm": 1.449519395828247,
      "learning_rate": 0.00010292230576441103,
      "loss": 6.015475,
      "step": 159000
    },
    {
      "epoch": 2.1217724448937783,
      "grad_norm": 1.4747400283813477,
      "learning_rate": 0.00010166917293233083,
      "loss": 6.011525,
      "step": 159500
    },
    {
      "epoch": 2.1284237691724424,
      "grad_norm": 1.4658464193344116,
      "learning_rate": 0.00010041604010025063,
      "loss": 6.0109,
      "step": 160000
    },
    {
      "epoch": 2.1284237691724424,
      "eval_loss": 6.025139331817627,
      "eval_runtime": 52.5341,
      "eval_samples_per_second": 951.764,
      "eval_steps_per_second": 7.443,
      "step": 160000
    },
    {
      "epoch": 2.135075093451106,
      "grad_norm": 1.4742381572723389,
      "learning_rate": 9.916290726817043e-05,
      "loss": 6.010525,
      "step": 160500
    },
    {
      "epoch": 2.14172641772977,
      "grad_norm": 1.526961088180542,
      "learning_rate": 9.790977443609022e-05,
      "loss": 6.011075,
      "step": 161000
    },
    {
      "epoch": 2.148377742008434,
      "grad_norm": 1.5673530101776123,
      "learning_rate": 9.665914786967418e-05,
      "loss": 6.0093,
      "step": 161500
    },
    {
      "epoch": 2.155029066287098,
      "grad_norm": 1.5154248476028442,
      "learning_rate": 9.540601503759399e-05,
      "loss": 6.01015,
      "step": 162000
    },
    {
      "epoch": 2.1616803905657616,
      "grad_norm": 1.5477021932601929,
      "learning_rate": 9.415538847117795e-05,
      "loss": 6.008375,
      "step": 162500
    },
    {
      "epoch": 2.1683317148444257,
      "grad_norm": 1.5632357597351074,
      "learning_rate": 9.290225563909775e-05,
      "loss": 6.00785,
      "step": 163000
    },
    {
      "epoch": 2.1749830391230893,
      "grad_norm": 1.5241132974624634,
      "learning_rate": 9.164912280701756e-05,
      "loss": 6.0059,
      "step": 163500
    },
    {
      "epoch": 2.1816343634017534,
      "grad_norm": 1.3953083753585815,
      "learning_rate": 9.039598997493734e-05,
      "loss": 6.005675,
      "step": 164000
    },
    {
      "epoch": 2.1816343634017534,
      "eval_loss": 6.020445823669434,
      "eval_runtime": 52.5797,
      "eval_samples_per_second": 950.938,
      "eval_steps_per_second": 7.436,
      "step": 164000
    },
    {
      "epoch": 2.188285687680417,
      "grad_norm": 1.3795928955078125,
      "learning_rate": 8.914285714285715e-05,
      "loss": 6.005625,
      "step": 164500
    },
    {
      "epoch": 2.194937011959081,
      "grad_norm": 1.5734666585922241,
      "learning_rate": 8.788972431077695e-05,
      "loss": 6.00575,
      "step": 165000
    },
    {
      "epoch": 2.201588336237745,
      "grad_norm": 1.5192654132843018,
      "learning_rate": 8.663659147869675e-05,
      "loss": 6.005275,
      "step": 165500
    },
    {
      "epoch": 2.208239660516409,
      "grad_norm": 1.6819194555282593,
      "learning_rate": 8.538345864661655e-05,
      "loss": 6.003975,
      "step": 166000
    },
    {
      "epoch": 2.2148909847950726,
      "grad_norm": 1.3922516107559204,
      "learning_rate": 8.41328320802005e-05,
      "loss": 6.0037,
      "step": 166500
    },
    {
      "epoch": 2.2215423090737367,
      "grad_norm": 1.593930959701538,
      "learning_rate": 8.287969924812031e-05,
      "loss": 6.005325,
      "step": 167000
    },
    {
      "epoch": 2.2281936333524004,
      "grad_norm": 1.5891680717468262,
      "learning_rate": 8.162656641604011e-05,
      "loss": 6.00385,
      "step": 167500
    },
    {
      "epoch": 2.2348449576310645,
      "grad_norm": 1.4289404153823853,
      "learning_rate": 8.03734335839599e-05,
      "loss": 6.0008,
      "step": 168000
    },
    {
      "epoch": 2.2348449576310645,
      "eval_loss": 6.015403747558594,
      "eval_runtime": 57.026,
      "eval_samples_per_second": 876.793,
      "eval_steps_per_second": 6.857,
      "step": 168000
    },
    {
      "epoch": 2.241496281909728,
      "grad_norm": 1.6020987033843994,
      "learning_rate": 7.91203007518797e-05,
      "loss": 6.00215,
      "step": 168500
    },
    {
      "epoch": 2.2481476061883923,
      "grad_norm": 1.4960572719573975,
      "learning_rate": 7.786967418546366e-05,
      "loss": 6.0016,
      "step": 169000
    },
    {
      "epoch": 2.254798930467056,
      "grad_norm": 1.4913491010665894,
      "learning_rate": 7.661654135338345e-05,
      "loss": 6.00275,
      "step": 169500
    },
    {
      "epoch": 2.26145025474572,
      "grad_norm": 1.398938775062561,
      "learning_rate": 7.536340852130326e-05,
      "loss": 5.9993,
      "step": 170000
    },
    {
      "epoch": 2.2681015790243837,
      "grad_norm": 1.7401509284973145,
      "learning_rate": 7.411027568922306e-05,
      "loss": 5.998625,
      "step": 170500
    },
    {
      "epoch": 2.274752903303048,
      "grad_norm": 1.4463567733764648,
      "learning_rate": 7.285964912280702e-05,
      "loss": 5.999675,
      "step": 171000
    },
    {
      "epoch": 2.2814042275817115,
      "grad_norm": 1.576114296913147,
      "learning_rate": 7.160651629072681e-05,
      "loss": 6.001225,
      "step": 171500
    },
    {
      "epoch": 2.2880555518603756,
      "grad_norm": 1.6387505531311035,
      "learning_rate": 7.035338345864661e-05,
      "loss": 5.9967,
      "step": 172000
    },
    {
      "epoch": 2.2880555518603756,
      "eval_loss": 6.011420726776123,
      "eval_runtime": 52.4892,
      "eval_samples_per_second": 952.576,
      "eval_steps_per_second": 7.449,
      "step": 172000
    },
    {
      "epoch": 2.2947068761390392,
      "grad_norm": 1.4267429113388062,
      "learning_rate": 6.910025062656642e-05,
      "loss": 5.9985,
      "step": 172500
    },
    {
      "epoch": 2.3013582004177033,
      "grad_norm": 1.4089328050613403,
      "learning_rate": 6.784962406015038e-05,
      "loss": 6.0002,
      "step": 173000
    },
    {
      "epoch": 2.308009524696367,
      "grad_norm": 1.4932724237442017,
      "learning_rate": 6.659899749373434e-05,
      "loss": 5.9973,
      "step": 173500
    },
    {
      "epoch": 2.314660848975031,
      "grad_norm": 1.5257128477096558,
      "learning_rate": 6.534586466165414e-05,
      "loss": 5.997125,
      "step": 174000
    },
    {
      "epoch": 2.3213121732536948,
      "grad_norm": 1.5727406740188599,
      "learning_rate": 6.409273182957393e-05,
      "loss": 5.997125,
      "step": 174500
    },
    {
      "epoch": 2.327963497532359,
      "grad_norm": 1.622481107711792,
      "learning_rate": 6.283959899749374e-05,
      "loss": 5.9944,
      "step": 175000
    },
    {
      "epoch": 2.3346148218110225,
      "grad_norm": 1.4744824171066284,
      "learning_rate": 6.158646616541354e-05,
      "loss": 5.994975,
      "step": 175500
    },
    {
      "epoch": 2.3412661460896866,
      "grad_norm": 1.4967868328094482,
      "learning_rate": 6.0333333333333334e-05,
      "loss": 5.995425,
      "step": 176000
    },
    {
      "epoch": 2.3412661460896866,
      "eval_loss": 6.007377624511719,
      "eval_runtime": 52.4894,
      "eval_samples_per_second": 952.573,
      "eval_steps_per_second": 7.449,
      "step": 176000
    },
    {
      "epoch": 2.3479174703683503,
      "grad_norm": 1.526138186454773,
      "learning_rate": 5.9080200501253136e-05,
      "loss": 5.995275,
      "step": 176500
    },
    {
      "epoch": 2.3545687946470144,
      "grad_norm": 1.468817949295044,
      "learning_rate": 5.782706766917294e-05,
      "loss": 5.992175,
      "step": 177000
    },
    {
      "epoch": 2.361220118925678,
      "grad_norm": 1.4885003566741943,
      "learning_rate": 5.6573934837092735e-05,
      "loss": 5.99495,
      "step": 177500
    },
    {
      "epoch": 2.367871443204342,
      "grad_norm": 1.5632487535476685,
      "learning_rate": 5.532330827067669e-05,
      "loss": 5.99205,
      "step": 178000
    },
    {
      "epoch": 2.374522767483006,
      "grad_norm": 1.577385425567627,
      "learning_rate": 5.4070175438596494e-05,
      "loss": 5.992675,
      "step": 178500
    },
    {
      "epoch": 2.38117409176167,
      "grad_norm": 1.5192134380340576,
      "learning_rate": 5.281704260651629e-05,
      "loss": 5.990675,
      "step": 179000
    },
    {
      "epoch": 2.3878254160403336,
      "grad_norm": 1.5296905040740967,
      "learning_rate": 5.156390977443609e-05,
      "loss": 5.99205,
      "step": 179500
    },
    {
      "epoch": 2.3944767403189973,
      "grad_norm": 1.607053279876709,
      "learning_rate": 5.0313283208020055e-05,
      "loss": 5.99105,
      "step": 180000
    },
    {
      "epoch": 2.3944767403189973,
      "eval_loss": 6.003437042236328,
      "eval_runtime": 56.4958,
      "eval_samples_per_second": 885.022,
      "eval_steps_per_second": 6.921,
      "step": 180000
    },
    {
      "epoch": 2.4011280645976614,
      "grad_norm": 1.5787283182144165,
      "learning_rate": 4.906015037593985e-05,
      "loss": 5.990325,
      "step": 180500
    },
    {
      "epoch": 2.4077793888763255,
      "grad_norm": 1.6039209365844727,
      "learning_rate": 4.780701754385965e-05,
      "loss": 5.9885,
      "step": 181000
    },
    {
      "epoch": 2.414430713154989,
      "grad_norm": 1.565821647644043,
      "learning_rate": 4.6553884711779456e-05,
      "loss": 5.988675,
      "step": 181500
    },
    {
      "epoch": 2.421082037433653,
      "grad_norm": 1.4805995225906372,
      "learning_rate": 4.5303258145363406e-05,
      "loss": 5.990775,
      "step": 182000
    },
    {
      "epoch": 2.427733361712317,
      "grad_norm": 1.7214000225067139,
      "learning_rate": 4.405012531328321e-05,
      "loss": 5.988575,
      "step": 182500
    },
    {
      "epoch": 2.434384685990981,
      "grad_norm": 1.5922911167144775,
      "learning_rate": 4.279699248120301e-05,
      "loss": 5.986475,
      "step": 183000
    },
    {
      "epoch": 2.4410360102696447,
      "grad_norm": 1.5732501745224,
      "learning_rate": 4.1543859649122806e-05,
      "loss": 5.988225,
      "step": 183500
    },
    {
      "epoch": 2.4476873345483083,
      "grad_norm": 1.4940141439437866,
      "learning_rate": 4.029323308270677e-05,
      "loss": 5.98515,
      "step": 184000
    },
    {
      "epoch": 2.4476873345483083,
      "eval_loss": 5.999696254730225,
      "eval_runtime": 52.4648,
      "eval_samples_per_second": 953.021,
      "eval_steps_per_second": 7.453,
      "step": 184000
    },
    {
      "epoch": 2.4543386588269724,
      "grad_norm": 1.6297956705093384,
      "learning_rate": 3.904010025062657e-05,
      "loss": 5.988575,
      "step": 184500
    },
    {
      "epoch": 2.4609899831056365,
      "grad_norm": 1.8519047498703003,
      "learning_rate": 3.778696741854637e-05,
      "loss": 5.9866,
      "step": 185000
    },
    {
      "epoch": 2.4676413073843,
      "grad_norm": 1.6281228065490723,
      "learning_rate": 3.653383458646617e-05,
      "loss": 5.98535,
      "step": 185500
    },
    {
      "epoch": 2.474292631662964,
      "grad_norm": 1.8047391176223755,
      "learning_rate": 3.5280701754385966e-05,
      "loss": 5.98495,
      "step": 186000
    },
    {
      "epoch": 2.480943955941628,
      "grad_norm": 1.6147902011871338,
      "learning_rate": 3.402756892230577e-05,
      "loss": 5.987,
      "step": 186500
    },
    {
      "epoch": 2.487595280220292,
      "grad_norm": 1.6247508525848389,
      "learning_rate": 3.277443609022557e-05,
      "loss": 5.9845,
      "step": 187000
    },
    {
      "epoch": 2.4942466044989557,
      "grad_norm": 1.5172460079193115,
      "learning_rate": 3.152130325814537e-05,
      "loss": 5.983775,
      "step": 187500
    },
    {
      "epoch": 2.5008979287776194,
      "grad_norm": 1.6825520992279053,
      "learning_rate": 3.0270676691729323e-05,
      "loss": 5.984875,
      "step": 188000
    },
    {
      "epoch": 2.5008979287776194,
      "eval_loss": 5.996800422668457,
      "eval_runtime": 52.4808,
      "eval_samples_per_second": 952.729,
      "eval_steps_per_second": 7.45,
      "step": 188000
    },
    {
      "epoch": 2.5075492530562835,
      "grad_norm": 1.5505605936050415,
      "learning_rate": 2.9017543859649122e-05,
      "loss": 5.984475,
      "step": 188500
    },
    {
      "epoch": 2.5142005773349476,
      "grad_norm": 1.5421501398086548,
      "learning_rate": 2.776441102756892e-05,
      "loss": 5.983875,
      "step": 189000
    },
    {
      "epoch": 2.5208519016136113,
      "grad_norm": 1.5193227529525757,
      "learning_rate": 2.651127819548872e-05,
      "loss": 5.9837,
      "step": 189500
    },
    {
      "epoch": 2.527503225892275,
      "grad_norm": 1.6437606811523438,
      "learning_rate": 2.526065162907268e-05,
      "loss": 5.981525,
      "step": 190000
    },
    {
      "epoch": 2.534154550170939,
      "grad_norm": 1.511576533317566,
      "learning_rate": 2.401002506265664e-05,
      "loss": 5.9822,
      "step": 190500
    },
    {
      "epoch": 2.540805874449603,
      "grad_norm": 1.6926944255828857,
      "learning_rate": 2.275689223057644e-05,
      "loss": 5.9806,
      "step": 191000
    },
    {
      "epoch": 2.547457198728267,
      "grad_norm": 1.6589057445526123,
      "learning_rate": 2.1503759398496242e-05,
      "loss": 5.9816,
      "step": 191500
    },
    {
      "epoch": 2.5541085230069305,
      "grad_norm": 1.5826290845870972,
      "learning_rate": 2.025062656641604e-05,
      "loss": 5.98285,
      "step": 192000
    },
    {
      "epoch": 2.5541085230069305,
      "eval_loss": 5.993854999542236,
      "eval_runtime": 52.9154,
      "eval_samples_per_second": 944.905,
      "eval_steps_per_second": 7.389,
      "step": 192000
    },
    {
      "epoch": 2.5607598472855946,
      "grad_norm": 1.4195935726165771,
      "learning_rate": 1.899749373433584e-05,
      "loss": 5.980775,
      "step": 192500
    },
    {
      "epoch": 2.5674111715642587,
      "grad_norm": 1.4777907133102417,
      "learning_rate": 1.774436090225564e-05,
      "loss": 5.98145,
      "step": 193000
    },
    {
      "epoch": 2.5740624958429223,
      "grad_norm": 1.6826404333114624,
      "learning_rate": 1.649122807017544e-05,
      "loss": 5.9802,
      "step": 193500
    },
    {
      "epoch": 2.580713820121586,
      "grad_norm": 1.4337778091430664,
      "learning_rate": 1.5238095238095238e-05,
      "loss": 5.97935,
      "step": 194000
    },
    {
      "epoch": 2.58736514440025,
      "grad_norm": 1.5586371421813965,
      "learning_rate": 1.3987468671679197e-05,
      "loss": 5.980175,
      "step": 194500
    },
    {
      "epoch": 2.5940164686789142,
      "grad_norm": 1.640689492225647,
      "learning_rate": 1.2734335839598998e-05,
      "loss": 5.97765,
      "step": 195000
    },
    {
      "epoch": 2.600667792957578,
      "grad_norm": 1.8467763662338257,
      "learning_rate": 1.1481203007518797e-05,
      "loss": 5.97845,
      "step": 195500
    },
    {
      "epoch": 2.6073191172362415,
      "grad_norm": 1.576478362083435,
      "learning_rate": 1.0228070175438596e-05,
      "loss": 5.9787,
      "step": 196000
    },
    {
      "epoch": 2.6073191172362415,
      "eval_loss": 5.9916205406188965,
      "eval_runtime": 56.5417,
      "eval_samples_per_second": 884.303,
      "eval_steps_per_second": 6.915,
      "step": 196000
    },
    {
      "epoch": 2.6139704415149057,
      "grad_norm": 1.3902900218963623,
      "learning_rate": 8.977443609022556e-06,
      "loss": 5.97745,
      "step": 196500
    },
    {
      "epoch": 2.6206217657935698,
      "grad_norm": 1.5065003633499146,
      "learning_rate": 7.724310776942356e-06,
      "loss": 5.97915,
      "step": 197000
    },
    {
      "epoch": 2.6272730900722334,
      "grad_norm": 1.5594068765640259,
      "learning_rate": 6.4711779448621555e-06,
      "loss": 5.976,
      "step": 197500
    },
    {
      "epoch": 2.633924414350897,
      "grad_norm": 1.5835047960281372,
      "learning_rate": 5.218045112781955e-06,
      "loss": 5.978625,
      "step": 198000
    },
    {
      "epoch": 2.640575738629561,
      "grad_norm": 1.5729209184646606,
      "learning_rate": 3.9674185463659145e-06,
      "loss": 5.97645,
      "step": 198500
    },
    {
      "epoch": 2.6472270629082253,
      "grad_norm": 1.5791716575622559,
      "learning_rate": 2.7142857142857144e-06,
      "loss": 5.9779,
      "step": 199000
    },
    {
      "epoch": 2.653878387186889,
      "grad_norm": 1.560107707977295,
      "learning_rate": 1.4611528822055138e-06,
      "loss": 5.976775,
      "step": 199500
    },
    {
      "epoch": 2.6605297114655526,
      "grad_norm": 1.5328997373580933,
      "learning_rate": 2.0802005012531329e-07,
      "loss": 5.97705,
      "step": 200000
    },
    {
      "epoch": 2.6605297114655526,
      "eval_loss": 5.990121841430664,
      "eval_runtime": 56.9988,
      "eval_samples_per_second": 877.212,
      "eval_steps_per_second": 6.86,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}